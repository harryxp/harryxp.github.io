<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
        <title>Peachful Space - Handling Large Number of Rows in Postgres</title>
        <link href="https://fonts.googleapis.com/css?family=Work+Sans" rel="stylesheet">
        <link rel="stylesheet" type="text/css" href="../css/default.css" />
    </head>
    <body>
        <div id="header">
            <div id="logo">
                <a href="../">Peachful Space</a>
            </div>
            <div id="navigation">
                <a href="../">Home</a>
                <a href="../about.html">About</a>
                <a href="../archive.html">Archive</a>
            </div>
        </div>

        <div id="content">
            <h1>Handling Large Number of Rows in Postgres</h1>

            <div class="info">
    Posted on April 28, 2015
    
</div>

<p>I have a pretty big Postgres table of nearly 50+ million rows. Well, I shouldn’t - I should have partitioned it, or used whatever strategy suitable for dealing with such volume of data. But let’s say the way the system was set up doesn’t allow it so I have to deal with one monolithic table.</p>
<p>The use case is to loop over all the rows in this table programmatically. In Perl we can use the <code>DBI</code> library:</p>
<pre><code>my $dbh = DBI-&gt;connect(...);
my $sth = $dbh-&gt;prepare('select * from giant_table');
$dbh-&gt;execute();
while (my $ary_ref = $sth-&gt;fetchrow_arrayref()) {
    # do something with $ary_ref ...
}
$dbh-&gt;disconnect();</code></pre>
<p>You’d think, given that <code>fetchrow_arrayref()</code> returns only one row, it’d be smart about it. That is, rather than retrieve all the 50+ million rows altogether, build some kind of internal cache far smaller and move data one batch at a time. Well, it doesn’t. It took me a while to figure out that <code>execute()</code> moves all the data from target dataset into memory. (Pro tip: just add <code>sleep(60);</code> after <code>execute()</code> and watch <code>htop</code>.)</p>
<p>Actually I think it’s reasonable to implement it this way. First, this makes the behavior of <code>execute()</code> consistent across datasets of different sizes. Second, cursors solve exactly this and <code>DBI</code>, at least <code>DBD::pg</code>, provides a way to do it. You just need to be more explicit about it. <a href="http://search.cpan.org/dist/DBD-Pg/Pg.pm#Cursors">See the solution here.</a></p>

        </div>
        <div id="footer">
            Site proudly generated by
            <a href="http://jaspervdj.be/hakyll">Hakyll</a>
        </div>
    </body>
</html>
